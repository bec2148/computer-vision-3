{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bec2148/computer-vision-3/blob/main/Homework3_Release_Updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1ba25aa-1137-4740-839c-f7a69eb50b52"
      },
      "source": [
        "Homework 3: Object Recognition\n",
        "==========\n",
        "\n",
        "> **Submission Instructions:** Before the deadline, export the completed notebook to PDF and upload it to GradeScope. The PDF should clearly show your code, and the result of running the code. Check the PDF to ensure that it is readable, the font-size is not small, and no information is cut-off. There will be no make-ups or extensions for corrupted/damaged/unreadable PDFs."
      ],
      "id": "c1ba25aa-1137-4740-839c-f7a69eb50b52"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVcwnnUJjQEj"
      },
      "source": [
        "Brendan Cunnie  `bec2148`\n",
        "\n",
        "**Names of Collaborators:** Coded with help from ChatGPT, eager assistance from CoPilot, and much Googling.  And I looked at an implementation of resnet that I had coded for a previous class.\n",
        "\n",
        "In this homework, we will investigate learning a neural network with PyTorch. This will give you some familarity with PyTorch and modern deep learning libraries. First, let's load in PyTorch and several functions that we will use throughout the homework."
      ],
      "id": "AVcwnnUJjQEj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "071258a6-b275-4a24-ad8e-1e7663b2584b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "id": "071258a6-b275-4a24-ad8e-1e7663b2584b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lwxFsRf1Tkt"
      },
      "source": [
        "For this homework, having access to a GPU will be very useful. To enable a GPU, follow the instructions from the previous homework. If the code below outputs `cuda`, then you are using a GPU."
      ],
      "id": "4lwxFsRf1Tkt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zhdwrJ51deT"
      },
      "outputs": [],
      "source": [
        "print(device)"
      ],
      "id": "1zhdwrJ51deT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Problem 1: Building Neural Network"
      ],
      "metadata": {
        "id": "gV5Hmnr6avzU"
      },
      "id": "gV5Hmnr6avzU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ab7cefb-1ca9-4361-826c-9fffe3068278"
      },
      "source": [
        "Introduction to PyTorch\n",
        "-----------------------\n",
        "PyTorch is similar to numpy. For the most part, if there is a numpy operation, there is an equivalent PyTorch operation. However, the advantage of PyTorch is that it will automatically calculate gradients through back-propagation and the algorithms are implemented on the GPU.\n",
        "\n",
        "### Automatic Differentiation\n",
        "You can view PyTorch as Numpy with gradient calculation built in. After you have finished computing your program, there is a `.backward()` function that calculates the gradients for all of the operations in the program. You no longer need to analytically calculate the gradients, code it up, and write a gradient checker.\n",
        "\n",
        "Let's look at a basic example. We will perform matrix multiplication between `a` and `b`, followed by element-wise multiplication with `c`, and finally we sum the result. Since it is computed in PyTorch, we can simply call `result.backward()` to have all of the gradients calculated throughout the computational graph."
      ],
      "id": "7ab7cefb-1ca9-4361-826c-9fffe3068278"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a645f82-d24e-4205-9bfd-c442a83e82ad"
      },
      "outputs": [],
      "source": [
        "a = torch.rand(2,2, requires_grad=True, device=device)\n",
        "b = torch.rand(2,2, requires_grad=True, device=device)\n",
        "c = torch.rand(2,2, device=device)\n",
        "\n",
        "result = torch.matmul(a, b) * c\n",
        "result = result.sum()\n",
        "\n",
        "result.backward() # calculate the gradients with back-propagation to the input\n",
        "\n",
        "print(f'Result: {result.cpu().item()}')\n",
        "print(f'Gradient a:\\n {a.grad}')\n",
        "print(f'Gradient b:\\n {b.grad}')\n",
        "print(f'Gradient c:\\n {c.grad}')"
      ],
      "id": "6a645f82-d24e-4205-9bfd-c442a83e82ad"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX7MOdFf2j6-"
      },
      "source": [
        "Note that only the tensors explicitly marked with `requires_grad=True` will have gradients calculated. Consequently, the gradient for `c` is `None` in the above computation. Automatic differenation makes it possible to implement very creative and complex deep learning algorithms. There has been extensive research and development to create many differentiable functions.\n",
        "\n",
        "PyTorch makes it easy to transfer variables between the CPU and the GPU. When the variable `a` is constructed, the `device=device` specifies whether to store it on the CPU or GPU, depending on the value of the `device` variable. There is also a `.cpu()` function to bring a variable back to the CPU, and a `.to(device)` function to transfer a variable between devices."
      ],
      "id": "IX7MOdFf2j6-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhSdPdR--tXE"
      },
      "outputs": [],
      "source": [
        "cpu_tensor = torch.rand(2,2)\n",
        "gpu_tensor = cpu_tensor.to(\"cuda\")\n",
        "\n",
        "cpu_tensor_2 = gpu_tensor.to(\"cpu\")\n",
        "cpu_tensor_3 = gpu_tensor.cpu()"
      ],
      "id": "YhSdPdR--tXE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f394f66-027b-4e72-b1a4-5f8d576682f9"
      },
      "source": [
        "### Neural Network Layers\n",
        "\n",
        "PyTorch also has a large library of deep learning layers. These layers allow you to operate at a higher-level of abstraction than low-level code. For example, one of the most basic layers in deep learning modules are linear layers, which is a matrix multiplication followed by a vector addition. PyTorch has layers that handle this for you, and automatically create the parameter vectors that need to be learned.\n",
        "\n",
        "Below is an example. Notice how we first create the layer, then we call the layer. Creating the layer is like creating the function, which you can then later call. When the layer is created, the weights for the matrix multiplication (and addition) are automatically created, and initialized automatically with random numbers."
      ],
      "id": "9f394f66-027b-4e72-b1a4-5f8d576682f9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d9cccd5-393d-4b99-9de9-34dbc7d40413"
      },
      "outputs": [],
      "source": [
        "test_input = torch.randn(3)\n",
        "\n",
        "layer = nn.Linear(3, 2) # create the layer\n",
        "output = layer(test_input) # call the layer\n",
        "\n",
        "print('Weights of the Layer:')\n",
        "print(layer.weight)"
      ],
      "id": "4d9cccd5-393d-4b99-9de9-34dbc7d40413"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a5f2e58-9478-4ed6-8b6b-a694cd92d224"
      },
      "source": [
        "This allows us to chain layers together in order to create a neural network. For example, the below code creates a neural network similar to the previous homework. And the gradients can be easily calculated through back-propagation throughout all of the layers."
      ],
      "id": "6a5f2e58-9478-4ed6-8b6b-a694cd92d224"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f93a2cb5-f028-4761-bb8d-3402cba55ce0"
      },
      "outputs": [],
      "source": [
        "test_input = torch.randn(3)\n",
        "\n",
        "layer1 = nn.Linear(3, 20)\n",
        "layer2 = nn.ReLU()\n",
        "layer3 = nn.Linear(20, 1)\n",
        "\n",
        "out = layer1(test_input)\n",
        "out = layer2(out)\n",
        "out = layer3(out)\n",
        "\n",
        "print(f'Result: {out.item()}')\n",
        "\n",
        "out.backward()\n",
        "\n",
        "print('Gradient to weights in layer 1:')\n",
        "print(layer1.weight.grad)"
      ],
      "id": "f93a2cb5-f028-4761-bb8d-3402cba55ce0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7493f7bf-f020-4429-a4d2-772dfc1c0061"
      },
      "source": [
        "Let's use this knowledge to create a neural network for object recognition."
      ],
      "id": "7493f7bf-f020-4429-a4d2-772dfc1c0061"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2b040d5-ab97-4790-b423-428fc20ee752"
      },
      "source": [
        "Loading Image Datasets\n",
        "----------------------\n",
        "We are going to work with the CIFAR10 dataset, which is a small image dataset consisting of just ten object categories. Most datasets today are many orders of magnitude larger in size, but the smaller dataset will allow us to work on commodity computers. The code below will download both the train/test splits of the CIFAR10 dataset, and visualize some of the images."
      ],
      "id": "c2b040d5-ab97-4790-b423-428fc20ee752"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04121e8d-a42c-4287-a3ac-c7639d4a9175"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))"
      ],
      "id": "04121e8d-a42c-4287-a3ac-c7639d4a9175"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1aa6f00-c29f-47f6-be09-2582e363741c"
      },
      "source": [
        "Building the Neural Network\n",
        "---------------------------\n",
        "\n",
        "Create a convolutional neural network that classifies the category of the images in the CIFAR10 dataset. In the class below, there are two functions: `__init__` and `forward()`. In the constructor, instantiate the layers that you will need. In the `forward()` function, call these layers in order to run the neural network forwards.\n",
        "\n",
        "Experiment with the below neural network layers to build a network that is able to classify the image:\n",
        "- <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\">nn.Conv2d()</a>\n",
        "- <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d\">nn.MaxPool2d()</a>\n",
        "- <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\">nn.Linear()</a>\n",
        "- <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU\">nn.ReLU()</a>\n",
        "\n",
        "The input `x` will be an tensor of size `4x3x32x32`, which represents a batch of input images. The output should be a ten dimensional vector. You will most likely need to use other PyTorch operations as well, such as `torch.flatten()`. Feel free to use other layers and operations as you see fit.\n",
        "\n",
        "We recommend first trying the following neural network: convolution, max pooling, convolution, max pooling, convolution, convolution, flattening, linear, linear, linear. Note that you should put the activation function in the right spots."
      ],
      "id": "c1aa6f00-c29f-47f6-be09-2582e363741c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d51e46f1-581f-45d1-a093-ba63e7f09cb2"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # DONE: Initialized network layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # DONE: Implemented the forward pass with using the layers defined above\n",
        "        #       and the proper activation functions\n",
        "        c1 = self.conv1(x)\n",
        "        relu1 = F.relu(c1)\n",
        "        c2 = self.conv2(relu1)\n",
        "        relu2 = F.relu(c2)\n",
        "        pool2 = self.pool(relu2)\n",
        "        c3 = self.conv3(pool2)\n",
        "        relu3 = F.relu(c3)\n",
        "        c4 = self.conv4(relu3)\n",
        "        relu4 = F.relu(c4)\n",
        "        pool4 = self.pool(relu4)\n",
        "        # pool4.shape == [4, 128, 8, 8]\n",
        "        flattened = torch.flatten(pool4, start_dim=1)\n",
        "        # flattened.shape == [4, 8192]\n",
        "        # because fully connected layers (usually) expect 1D input.  (4 is the batch size.)\n",
        "        x = F.relu(self.fc1(flattened))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net()"
      ],
      "id": "d51e46f1-581f-45d1-a093-ba63e7f09cb2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e2c54f8-d9ed-4f64-8842-8c2493998195"
      },
      "source": [
        "Before we proceed, let's visualize the weights of the first convolutional layer in the neural network. Modify the code below in order to plot the weights of the first convolutional layer. (You need to use `detach()` in order for this to work.)"
      ],
      "id": "3e2c54f8-d9ed-4f64-8842-8c2493998195"
    },
    {
      "cell_type": "code",
      "source": [
        "# imshow(torchvision.utils.make_grid(net.conv1.weight.cpu().detach()))\n",
        "\n",
        "\n",
        "# Visualize the weights of the first convolutional layer\n",
        "# kernel_size=3\n",
        "weights = net.conv1.weight.cpu().detach() # move tensor to cpu. detach: we're visualizing, not training\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.axis(\"off\") # don't need axis; just showing weights\n",
        "# .permute(1, 2, 0)) to change PyTorche's (Channels, Height, Width) to plt's expected (Height, Width, Channels)\n",
        "plt.imshow(torchvision.utils.make_grid(weights, normalize=True, pad_value=1).permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y-8ATVm3UW3f"
      },
      "id": "y-8ATVm3UW3f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f271ca1-27e9-4233-bf9f-d63efce156db"
      },
      "source": [
        "Training the Network\n",
        "--------------------\n",
        "\n",
        "Since the neural network is initialized with random noise, the filters visualized above are just random noise. In order to train them, we need to specify both a) a loss function and b) an optimization algorithm. We will use the cross entropy loss function with stochastic gradient descent. In PyTorch, we can specify these by creating the two objects below:"
      ],
      "id": "3f271ca1-27e9-4233-bf9f-d63efce156db"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a3b8960-915a-41c8-b190-cc363234e779"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
      ],
      "id": "6a3b8960-915a-41c8-b190-cc363234e779"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c7296b0-2462-42ce-9da2-ef033b6a6afe"
      },
      "source": [
        "Notice that the optimizer accepts the parameter `net.parameters()`. The call `net.parameters()` is a bit of magic. It will automatically determine which tensors are learnable inside the network, and pack them into a vector that is fed into the gradient descent method. In the previous homework, you needed to manually track these variables, but in PyTorch there is book-keeping underneath the API that does this for you automatically.\n",
        "\n",
        "Now, we are ready to train the neural network."
      ],
      "id": "6c7296b0-2462-42ce-9da2-ef033b6a6afe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9af41bb4-2495-430f-aeb2-12a43a650c5c"
      },
      "outputs": [],
      "source": [
        "def train_network(net, n_epochs=2):\n",
        "    net.to(device)\n",
        "\n",
        "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            if i % 1000 == 0:\n",
        "                print(f'Epoch={epoch + 1} Iter={i + 1:5d} Loss={loss.item():.3f}')\n",
        "                running_loss = 0.0\n",
        "    print('Finished Training')\n",
        "    return net\n"
      ],
      "id": "9af41bb4-2495-430f-aeb2-12a43a650c5c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jirk3sAeFkVu"
      },
      "source": [
        "If you want, you can train the network for longer too. This will help improve the performance."
      ],
      "id": "Jirk3sAeFkVu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElCSzf5rFo4e"
      },
      "outputs": [],
      "source": [
        "train_network(net, n_epochs=5)"
      ],
      "id": "ElCSzf5rFo4e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "305157e1-2245-47d5-812d-215644430da9"
      },
      "source": [
        "Visualizing Predictions\n",
        "-----------------------\n",
        "\n",
        "Unless you train the neural network for a long time, the loss will most likely not go to zero. However, it should still go down, which means it has learned some association between visual patterns and the category labels in the dataset. Let's try the model on some images in the test set and see what it predicts for them."
      ],
      "id": "305157e1-2245-47d5-812d-215644430da9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f05ba9d4-608b-4fac-b49f-b0fa12daeeab"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "net.to(device)\n",
        "predictions = net(images.to(device)).argmax(axis=1).cpu().detach()\n",
        "accuracy = (labels==predictions).double().mean()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', '\\t'.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
        "print('Predictions: ', '\\t'.join(f'{classes[predictions[j]]:5s}' for j in range(4)))\n",
        "print(f'Accuracy: {accuracy*100}%')"
      ],
      "id": "f05ba9d4-608b-4fac-b49f-b0fa12daeeab"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf859ae6-ad61-468f-a08e-341f573a4c99"
      },
      "source": [
        "In our implementation, the predictions are not always correct, but they are often reasonable. This is impressive considering we have barely trained the neural network at all.\n",
        "\n",
        "Let's calculate the accuracy on the full test set."
      ],
      "id": "bf859ae6-ad61-468f-a08e-341f573a4c99"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-wrtPwLFxoD"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(testloader)\n",
        "\n",
        "running_accuracy = 0\n",
        "running_count = 0\n",
        "for images, labels in dataiter:\n",
        "  images = images.to(device)\n",
        "  predictions = net(images.to(device)).argmax(axis=1).cpu().detach()\n",
        "  accuracy = (labels==predictions).double().mean()\n",
        "\n",
        "  running_accuracy += accuracy\n",
        "  running_count += 1\n",
        "\n",
        "print(f'Accuracy: {running_accuracy/running_count*100:.2f}%')"
      ],
      "id": "z-wrtPwLFxoD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkbTTQh-GMsJ"
      },
      "source": [
        "In our solution, we get 74% accuracy after training for about 10 minutes on the Colab GPU. Can you do better?"
      ],
      "id": "IkbTTQh-GMsJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Problem 2: Building ResNet"
      ],
      "metadata": {
        "id": "Pgg9f07ea-WR"
      },
      "id": "Pgg9f07ea-WR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0a85af2-ccc8-4dc1-adde-9a83e6a69c1e"
      },
      "source": [
        "Residual Network\n",
        "----------------\n",
        "\n",
        "Residual networks have become a standard architecture because they are able to efficiently scale to a large number of layers. While the state-of-the-art networks have thousands of layers, they would be too expensive to train in time for the homework deadline. Let's implement just a simple residual network.\n",
        "\n",
        "Implement a ResNet block which contains convolutional layers with a skip connection across them. Note that the dimensions of the original input and the output of the convolutional layers may not match up for addition. Hint: one way to address this is to introduce a linear transformation (like a 1x1 kernel convolution) to resize the input when necessary. Another would be to 0-pad the input to match dimensions for addition."
      ],
      "id": "b0a85af2-ccc8-4dc1-adde-9a83e6a69c1e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "384f7579-1789-4303-bee8-a8678bf83c1e"
      },
      "outputs": [],
      "source": [
        "# Code largely taken from an implementation I had done in a previous class,\n",
        "# which relied on open source implementation https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py\n",
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        # DONE: Initializing Two Convolutional Layers in the Residual Block\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        # Google recommended batch normalization to stabilize training and speed up learning rates\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.skip_connection = nn.Identity()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            # DONE: Using a Conv2d layer with kernel_size=1 to \"resize\" input\n",
        "            self.skip_connection = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
        "                          stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity_x = self.skip_connection(x)\n",
        "\n",
        "        # DONE: Implemented Forward pass using 2 Conv Layers.\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        assert out.shape == identity_x.shape\n",
        "        out += identity_x\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "id": "384f7579-1789-4303-bee8-a8678bf83c1e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhLgqItzzjKd"
      },
      "source": [
        "\n",
        "In the code block below, complete the class for a residual network. (PyTorch has a residual network built in, but you should not use it. Instead, create a residual network using the building blocks introduced above.) We recommend the following architecture: Convolution, Maxpooling, ResNetBlock, ResNetBlock, flatten, linear, linear, linear. Be sure to use ReLU activations where necessary. Try experimenting with different channel dimensions."
      ],
      "id": "yhLgqItzzjKd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TOzYmQ7xhev"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # DONE: initialize network layers\n",
        "        # Initial convolution and pooling\n",
        "\n",
        "        # CIFAR-10 has 3 input channels\n",
        "        self.conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Two ResNet blocks\n",
        "        self.block1 = ResNetBlock(64, 128, stride=2)\n",
        "        self.block2 = ResNetBlock(128, 128, stride=1)\n",
        "\n",
        "        # After conv + pool + block1 (stride=2), spatial dims go from 32x32 → 16x16 → 8x8\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)  # 10 classes for CIFAR-10\n",
        "\n",
        "    def forward(self, x):\n",
        "        # DONE: Implemented forward pass\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Instantiate the network\n",
        "res_net = ResNet()"
      ],
      "id": "6TOzYmQ7xhev"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj2sTvHCsvHz"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(res_net.parameters(), lr=0.0001)"
      ],
      "id": "zj2sTvHCsvHz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7a2b9e2-beed-44b5-a606-8a3fb5e001d9"
      },
      "source": [
        "After you create the network, we can use the training loop from above in order to train it."
      ],
      "id": "b7a2b9e2-beed-44b5-a606-8a3fb5e001d9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9df8b4af-01a1-41d1-aa3b-013cc02db777"
      },
      "outputs": [],
      "source": [
        "res_net = train_network(res_net, n_epochs=5)"
      ],
      "id": "9df8b4af-01a1-41d1-aa3b-013cc02db777"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "937175d9-7c35-4715-9c78-d2f441291071"
      },
      "source": [
        "Let's visualize some of the predictions from the trained network."
      ],
      "id": "937175d9-7c35-4715-9c78-d2f441291071"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bad6cdf-c4c7-4975-936d-40df5fc19073"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "res_net.to(device)\n",
        "predictions = res_net(images.to(device)).argmax(axis=1).cpu().detach()\n",
        "accuracy = (labels==predictions).double().mean()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', '\\t'.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
        "print('Predictions: ', '\\t'.join(f'{classes[predictions[j]]:5s}' for j in range(4)))\n",
        "print(f'Accuracy: {accuracy*100}%')"
      ],
      "id": "9bad6cdf-c4c7-4975-936d-40df5fc19073"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCeChOne3L0o"
      },
      "source": [
        "Let's also calculate the accuracy on the full test set."
      ],
      "id": "gCeChOne3L0o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzSIvCTp28UF"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(testloader)\n",
        "\n",
        "running_accuracy = 0\n",
        "running_count = 0\n",
        "for images, labels in dataiter:\n",
        "  images = images.to(device)\n",
        "  predictions = res_net(images.to(device)).argmax(axis=1).cpu().detach()\n",
        "  accuracy = (labels==predictions).double().mean()\n",
        "\n",
        "  running_accuracy += accuracy\n",
        "  running_count += 1\n",
        "\n",
        "print(f'Accuracy: {running_accuracy/running_count*100:.2f}%')"
      ],
      "id": "NzSIvCTp28UF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our solution, we get 75% accuracy."
      ],
      "metadata": {
        "id": "eKKBmrW4WgEu"
      },
      "id": "eKKBmrW4WgEu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Debugging Tips:\n",
        "- Try increasing epochs or adjusting the learning rate.\n",
        "- Try increasing model capacity by changing the number of layers.\n",
        "- Check if Batch Norm is applied after every convolution."
      ],
      "metadata": {
        "id": "VJnViHjP8Ooy"
      },
      "id": "VJnViHjP8Ooy"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}